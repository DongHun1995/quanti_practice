{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a0bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from dongnet import dongnet12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90263025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available. Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available! Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c8ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(X, NBIT):\n",
    "    # 1. find threshold\n",
    "    alpha = np.max(X)\n",
    "    beta = np.min(X)\n",
    "    alpha_q = -2**(NBIT - 1)\n",
    "    beta_q = 2**(NBIT - 1) - 1\n",
    "\n",
    "    s = (beta - alpha) / (beta_q - alpha_q)\n",
    "    z = int((beta*alpha_q - alpha * beta_q) / (beta - alpha))\n",
    "\n",
    "    data_q = np.round(1/s * X + z, decimals=0)\n",
    "    data_q = np.clip(data_q, alpha_q, beta_q)    \n",
    "    data_q = data_q.astype(np.int8)\n",
    "        \n",
    "    data_qn = data_q\n",
    "    data_qn = data_qn.astype(np.int32)\n",
    "    data_qn = s * (data_qn - z)\n",
    "    data_qn = data_qn.astype(np.float32)\n",
    "    \n",
    "    return data_qn\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    #batch norm 고정, dropout 안함, gradient 계산안함\n",
    "    model.eval()\n",
    "    #model 파라미터를 지정한 device 메모리에 올림\n",
    "    model.to(device)\n",
    "\n",
    "    running_corrects = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        #텐서의 최대값과 index를 반환\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # inputs.size(0) 현재 mini-batch의 크기(input의 0번째 dimension 크기)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    print(\"Dongnet12 cifar100 Accuracy: {:.4f}\".format(eval_accuracy))\n",
    "    \n",
    "# Accuracy Quantized model\n",
    "def evaluate_qmodel(model, test_loader, device, NBIT):\n",
    "    \n",
    "    disallowed_layer_names = []\n",
    "    # linear operation, convolution, batchnorm\n",
    "    whitelist=[torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d, torch.nn.Conv3d, nn.BatchNorm2d]\n",
    "    whitelist_layer_types = tuple(whitelist)\n",
    "    eligible_modules_list = []\n",
    "    eligible_param_list = []\n",
    "    for name, mod in model.named_modules():\n",
    "        if isinstance(mod, whitelist_layer_types) and name not in disallowed_layer_names:\n",
    "            eligible_modules_list.append((name, mod))\n",
    "            eligible_param_list.append(name)\n",
    "    \n",
    "    #1. extract weigth\n",
    "    #2. quantized weight\n",
    "    #3. Load quantized weight into the model\n",
    "    for name, param in model.named_parameters():\n",
    "        layername = '.'.join(name.split('.')[:1])\n",
    "        layername2 = '.'.join(name.split('.')[:2])\n",
    "        if layername in eligible_param_list:\n",
    "            weight = param.cpu().detach().numpy()\n",
    "            dqn = quantize(weight, NBIT)\n",
    "            param.data = torch.from_numpy(dqn)\n",
    "        elif layername2 in eligible_param_list:\n",
    "            weight = param.cpu().detach().numpy()\n",
    "            dqn = quantize(weight, NBIT)\n",
    "            param.data = torch.from_numpy(dqn)\n",
    "            \n",
    "\n",
    "    #batch norm 고정, dropout 안함, gradient 계산안함\n",
    "    model.eval()\n",
    "    #model 파라미터를 지정한 device 메모리에 올림\n",
    "    model.to(device)\n",
    "\n",
    "    running_corrects = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        #텐서의 최대값과 index를 반환\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # inputs.size(0) 현재 mini-batch의 크기(input의 0번째 dimension 크기)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    print(\"{}bit quantize model cifar100 Accuracy : {:.4f}\".format(NBIT, eval_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650a44aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = dongnet12()\n",
    "model_dict = torch.load('model.pth', map_location=torch.device('cpu'))  # 상태 사전 로드\n",
    "model.load_state_dict(model_dict)  # 모델에 상태 사전 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5e822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        #padding을 4추가하고 이미지를 32 X 32로 자름\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        #이미지를 뒤집는다\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #텐서로 바꾼다\n",
    "        transforms.ToTensor(),\n",
    "        #각 채널별 평균, 표준편차``\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    # CIFAR10 train 데이터 가져오기\n",
    "    # We will use test set for validation and test in this project.\n",
    "    # Do not use test set for validation in practice!\n",
    "    # CIFAR10 test 데이터 가져오기\n",
    "train_set = torchvision.datasets.CIFAR100(root=\"data\", train=True, download=True, transform=train_transform) \n",
    "test_set = torchvision.datasets.CIFAR100(root=\"data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_sampler = torch.utils.data.RandomSampler(train_set)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
    "\n",
    "    #sampler은 dataset에서 데이터를 뽑아오는 역할, num_workers는 데이터를 읽어오는 프로세스 수\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set, batch_size=128,\n",
    "    sampler=train_sampler, num_workers=8)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set, batch_size=128,\n",
    "    sampler=test_sampler, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db711513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dongnet12 cifar100 Accuracy: 0.6911\n",
      "8bit quantize model cifar100 Accuracy : 0.6916\n"
     ]
    }
   ],
   "source": [
    "# LOSS, Accuracy 확인\n",
    "evaluate_model(model=model, test_loader=test_loader, device='cpu')\n",
    "evaluate_qmodel(model=model, test_loader=test_loader, device='cpu', NBIT=8)\n",
    "#torch.save(model.state_dict(), 'int8qmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e178b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
